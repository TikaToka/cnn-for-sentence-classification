{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('GalBook_Trial1': conda)"
  },
  "interpreter": {
   "hash": "0933dbd68c81f720053f1429412209114176850c7e7e4a09951cac4adc2024b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#load data\r\n",
    "from datasets import load_dataset\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "dataset = load_dataset(\"nsmc\")\r\n",
    "\r\n",
    "train_df = pd.DataFrame(dataset['train'])\r\n",
    "test_df = pd.DataFrame(dataset['test'])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 3.18kB [00:00, 1.58MB/s]                   \n",
      "Downloading: 1.67kB [00:00, 1.67MB/s]                 \n",
      "Using custom data configuration default\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading and preparing dataset nsmc/default (download: 18.62 MiB, generated: 20.90 MiB, post-processed: Unknown size, total: 39.52 MiB) to C:\\Users\\sgi40\\.cache\\huggingface\\datasets\\nsmc\\default\\1.1.0\\bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 14.6MB [00:01, 13.6MB/s]\n",
      "Downloading: 4.89MB [00:00, 9.81MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset nsmc downloaded and prepared to C:\\Users\\sgi40\\.cache\\huggingface\\datasets\\nsmc\\default\\1.1.0\\bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#simplify\r\n",
    "\r\n",
    "import re\r\n",
    "\r\n",
    "docs = dataset['train']['document'] + dataset['test']['document']\r\n",
    "label = dataset['train']['label'] + dataset['test']['label']\r\n",
    "\r\n",
    "processed_docs = [re.sub(\"[\\s]+\", \" \", re.sub(\"[^가-힣a-zA-Z0-9]\", \" \", doc)) for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "docs[20:50]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님',\n",
       " '보면서 웃지 않는 건 불가능하다',\n",
       " '재미없다 지루하고. 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남....바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 ; 이건 볼게없다 음식도 별로 안나오고, 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ㅡㅡ',\n",
       " '절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다.',\n",
       " '주제는 좋은데 중반부터 지루하다',\n",
       " '다 짤랐을꺼야. 그래서 납득할 수 없었던거야.. 그럴꺼야.. 꼭 그랬던걸꺼야..',\n",
       " 'kl2g 고추를 털어버려야 할텐데',\n",
       " '카밀라벨 발연기',\n",
       " '재밋는뎅',\n",
       " '센스있는 연출력..탁월한 캐스팅..90년대의 향수.. 그래서 9점..',\n",
       " '엄포스의 위력을 다시 한번 깨닫게 해준 적.남 꽃검사님도 연기 정말 좋았어요! 완전 명품드라마!',\n",
       " '졸쓰레기 진부하고말도안됌ㅋㅋ 아..시간아까워',\n",
       " '재밌는데 별점이 왜이리 낮은고',\n",
       " '1%라도 기대했던 내가 죄인입니다 죄인입니다....',\n",
       " '아직도 이 드라마는 내인생의 최고!',\n",
       " '패션에 대한 열정! 안나 윈투어!',\n",
       " '키이라 나이틀리가 연기하고자 했던건 대체 정신장애일까 틱장애일까',\n",
       " '허허...원작가 정신나간 유령이라... 재미있겠네요!',\n",
       " '포스터는 있어보이는데 관객은 114명이네',\n",
       " '이 영화가 왜 이렇게 저평가 받는지 모르겠다',\n",
       " '단순하면서 은은한 매력의 영화',\n",
       " \"'다 알바생인가 내용도 없고 무서운거도 없고 웃긴거도 하나도 없음 완전 별싱거운 영화.ㅇ.ㅇ내ㅇ시간 넘 아까움 .. . 완전 낚임\",\n",
       " '오게두어라! 서리한이 굶주렸다!',\n",
       " '정말 맘에 들어요. 그래서 또 보고싶은데 또 보는 방법이 없네? >.. ㅜㅡ',\n",
       " '윤제문이라는 멋진 배우를 발견하게 됐어요. 소소한 일탈이 잔잔한 미소를 머금게 합니다. 음악은 조금 아쉽네요ㅠㅠ 8점 주고 싶은데 평점 올리고 싶어 10점 줄게요^^',\n",
       " '평점에속지마시길시간낭비 돈낭비임',\n",
       " '리얼리티가 뛰어나긴 한데 큰 공감은 안간다. 이민기캐릭터는 정신의학상 분노조절장애 초기 증상일거다. 툭하면 사람패고 욕하고 물건 파손하고.. 조금 오바였음. 극 초반엔 신선했는데 가면 갈수록 이민기 정신상태 공감불가.',\n",
       " '마이너스는 왜없냐 ㅋ 뮤비 보고 영화수준 딱 알만하더군 ㅉㅉ 북한에서 이런거 만들라고 돈 대주던?',\n",
       " '난 우리영화를 사랑합니다....^^;',\n",
       " '데너리스 타르 가르엔...나도 용의주인이 되고 싶다...누이랑,근친상간이나 하고 다닐지라도,소설 속에선 제일 멋진 놈이 자이메 라니스터였는데,드라마속에선,드래곤(용)이 제일 멋지네(웃음)감독님 토르-2 다크 월드는 말아 잡수셨을지라도,기본 선방은 했음']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "processed_docs[20:50]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['나름 심오한 뜻도 있는 듯 그냥 학생이 선생과 놀아나는 영화는 절대 아님',\n",
       " '보면서 웃지 않는 건 불가능하다',\n",
       " '재미없다 지루하고 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남 바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 이건 볼게없다 음식도 별로 안나오고 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ',\n",
       " '절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다 ',\n",
       " '주제는 좋은데 중반부터 지루하다',\n",
       " '다 짤랐을꺼야 그래서 납득할 수 없었던거야 그럴꺼야 꼭 그랬던걸꺼야 ',\n",
       " 'kl2g 고추를 털어버려야 할텐데',\n",
       " '카밀라벨 발연기',\n",
       " '재밋는뎅',\n",
       " '센스있는 연출력 탁월한 캐스팅 90년대의 향수 그래서 9점 ',\n",
       " '엄포스의 위력을 다시 한번 깨닫게 해준 적 남 꽃검사님도 연기 정말 좋았어요 완전 명품드라마 ',\n",
       " '졸쓰레기 진부하고말도안됌 아 시간아까워',\n",
       " '재밌는데 별점이 왜이리 낮은고',\n",
       " '1 라도 기대했던 내가 죄인입니다 죄인입니다 ',\n",
       " '아직도 이 드라마는 내인생의 최고 ',\n",
       " '패션에 대한 열정 안나 윈투어 ',\n",
       " '키이라 나이틀리가 연기하고자 했던건 대체 정신장애일까 틱장애일까',\n",
       " '허허 원작가 정신나간 유령이라 재미있겠네요 ',\n",
       " '포스터는 있어보이는데 관객은 114명이네',\n",
       " '이 영화가 왜 이렇게 저평가 받는지 모르겠다',\n",
       " '단순하면서 은은한 매력의 영화',\n",
       " ' 다 알바생인가 내용도 없고 무서운거도 없고 웃긴거도 하나도 없음 완전 별싱거운 영화 내 시간 넘 아까움 완전 낚임',\n",
       " '오게두어라 서리한이 굶주렸다 ',\n",
       " '정말 맘에 들어요 그래서 또 보고싶은데 또 보는 방법이 없네 ',\n",
       " '윤제문이라는 멋진 배우를 발견하게 됐어요 소소한 일탈이 잔잔한 미소를 머금게 합니다 음악은 조금 아쉽네요 8점 주고 싶은데 평점 올리고 싶어 10점 줄게요 ',\n",
       " '평점에속지마시길시간낭비 돈낭비임',\n",
       " '리얼리티가 뛰어나긴 한데 큰 공감은 안간다 이민기캐릭터는 정신의학상 분노조절장애 초기 증상일거다 툭하면 사람패고 욕하고 물건 파손하고 조금 오바였음 극 초반엔 신선했는데 가면 갈수록 이민기 정신상태 공감불가 ',\n",
       " '마이너스는 왜없냐 뮤비 보고 영화수준 딱 알만하더군 북한에서 이런거 만들라고 돈 대주던 ',\n",
       " '난 우리영화를 사랑합니다 ',\n",
       " '데너리스 타르 가르엔 나도 용의주인이 되고 싶다 누이랑 근친상간이나 하고 다닐지라도 소설 속에선 제일 멋진 놈이 자이메 라니스터였는데 드라마속에선 드래곤 용 이 제일 멋지네 웃음 감독님 토르 2 다크 월드는 말아 잡수셨을지라도 기본 선방은 했음']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# tokenize\r\n",
    "\r\n",
    "# from konlpy.tag import Mecab\r\n",
    "\r\n",
    "# mecab = Mecab()\r\n",
    "\r\n",
    "# res = []\r\n",
    "\r\n",
    "# for doc in docs:\r\n",
    "#   tokenlist = mecab.pos(doc)\r\n",
    "#   for w in tokenlist:\r\n",
    "#     if w[1] in ['NNG', 'NNP', 'NNB', 'NNBC', 'NP' 'VV', 'VA', 'IC', 'SN', 'SL', 'MAG', 'MAJ']:\r\n",
    "#       res.append(w[1])\r\n",
    "\r\n",
    "from konlpy.tag import Okt\r\n",
    "import pickle\r\n",
    "\r\n",
    "okt = Okt()\r\n",
    "\r\n",
    "res = []\r\n",
    "\r\n",
    "import os\r\n",
    "if not os.path.isfile('senspos.pickle'):\r\n",
    "  for doc in docs:\r\n",
    "    tokenlist = okt.pos(doc)\r\n",
    "    temp = []\r\n",
    "    for w in tokenlist:\r\n",
    "      if w[1] in ['Noun', 'Verb', 'Adjective', 'Adverb', 'Exclamation', 'Foreign', 'Alpha', 'Number', 'Unknown']:\r\n",
    "        temp.append(w[0])\r\n",
    "    res.append(temp)\r\n",
    "\r\n",
    "  with open(\"senspos.pickle\", 'wb') as f:\r\n",
    "    pickle.dump(res, f)\r\n",
    "  \r\n",
    "else:\r\n",
    "  with open(\"senspos.pickle\", 'wb') as f:\r\n",
    "    res = pickle.load(save, f)\r\n",
    "  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# make v2v\r\n",
    "from gensim.models import Word2Vec\r\n",
    "\r\n",
    "w2v = Word2Vec(res, vector_size=300, window=5, min_count=5, workers=4, sg=1)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sgi40\\anaconda3\\envs\\Galbook_Trial1\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# padding\r\n",
    "maxlen = max(len(x) for x in res)\r\n",
    "padded_sens = []\r\n",
    "for i in range(len(res)):\r\n",
    "  sen = res[i]\r\n",
    "  temp = sen + [\"<PAD/>\"] * (maxlen - len(sen))\r\n",
    "  padded_sens.append(temp)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# vocab to index\r\n",
    "import nltk\r\n",
    "tokens = [t for d in padded_sens for t in d]\r\n",
    "text = nltk.Text(tokens, name='NSMC')\r\n",
    "word_count = text.vocab()\r\n",
    "vocabulary_inv = [x[0] for x in word_count.most_common()]\r\n",
    "vocabulary = {x:i for i, x in enumerate(vocabulary_inv)}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sgi40\\\\OneDrive\\\\WallPaper\\\\github\\\\cnn-for-sentence-classification\\\\src'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# word 2 vec\r\n",
    "from gensim.models import word2vec\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "w2v = word2vec.Word2Vec.load(\"../data/ko.bin\")  \r\n",
    "\r\n",
    "w2v = {k: w2v[w] if w in w2v else np.random.uniform(-0.25, 0.25, w2v.vector_size) for k, w in vocabulary_inv.items()}"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\sgi40\\\\anaconda3\\\\envs\\\\Galbook_Trial1\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0f797d97fc2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/ko.bin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw2v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw2v\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocabulary_inv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Galbook_Trial1\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1932\u001b[0m                 \u001b[1;34m\"Try loading older model using gensim-3.8.3, then re-saving, to restore \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1933\u001b[0m                 \"compatibility with current code.\")\n\u001b[1;32m-> 1934\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1936\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Galbook_Trial1\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \"\"\"\n\u001b[0;32m   1921\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1922\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Galbook_Trial1\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Galbook_Trial1\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \"\"\"\n\u001b[0;32m   1457\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\sgi40\\\\anaconda3\\\\envs\\\\Galbook_Trial1\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}