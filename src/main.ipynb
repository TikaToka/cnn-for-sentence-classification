{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('nlp': conda)"
  },
  "interpreter": {
   "hash": "b306fc9a4baaf5515baf43d83914e9872778cec54f9c49a6a8fd06629a9f9072"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#load data\r\n",
    "from datasets import load_dataset\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "dataset = load_dataset(\"nsmc\")\r\n",
    "\r\n",
    "train_df = pd.DataFrame(dataset['train'])\r\n",
    "test_df = pd.DataFrame(dataset['test'])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (C:\\Users\\ford0\\.cache\\huggingface\\datasets\\nsmc\\default\\1.1.0\\bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "docs[20:50]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님',\n",
       " '보면서 웃지 않는 건 불가능하다',\n",
       " '재미없다 지루하고. 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남....바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 ; 이건 볼게없다 음식도 별로 안나오고, 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ㅡㅡ',\n",
       " '절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다.',\n",
       " '주제는 좋은데 중반부터 지루하다',\n",
       " '다 짤랐을꺼야. 그래서 납득할 수 없었던거야.. 그럴꺼야.. 꼭 그랬던걸꺼야..',\n",
       " 'kl2g 고추를 털어버려야 할텐데',\n",
       " '카밀라벨 발연기',\n",
       " '재밋는뎅',\n",
       " '센스있는 연출력..탁월한 캐스팅..90년대의 향수.. 그래서 9점..',\n",
       " '엄포스의 위력을 다시 한번 깨닫게 해준 적.남 꽃검사님도 연기 정말 좋았어요! 완전 명품드라마!',\n",
       " '졸쓰레기 진부하고말도안됌ㅋㅋ 아..시간아까워',\n",
       " '재밌는데 별점이 왜이리 낮은고',\n",
       " '1%라도 기대했던 내가 죄인입니다 죄인입니다....',\n",
       " '아직도 이 드라마는 내인생의 최고!',\n",
       " '패션에 대한 열정! 안나 윈투어!',\n",
       " '키이라 나이틀리가 연기하고자 했던건 대체 정신장애일까 틱장애일까',\n",
       " '허허...원작가 정신나간 유령이라... 재미있겠네요!',\n",
       " '포스터는 있어보이는데 관객은 114명이네',\n",
       " '이 영화가 왜 이렇게 저평가 받는지 모르겠다',\n",
       " '단순하면서 은은한 매력의 영화',\n",
       " \"'다 알바생인가 내용도 없고 무서운거도 없고 웃긴거도 하나도 없음 완전 별싱거운 영화.ㅇ.ㅇ내ㅇ시간 넘 아까움 .. . 완전 낚임\",\n",
       " '오게두어라! 서리한이 굶주렸다!',\n",
       " '정말 맘에 들어요. 그래서 또 보고싶은데 또 보는 방법이 없네? >.. ㅜㅡ',\n",
       " '윤제문이라는 멋진 배우를 발견하게 됐어요. 소소한 일탈이 잔잔한 미소를 머금게 합니다. 음악은 조금 아쉽네요ㅠㅠ 8점 주고 싶은데 평점 올리고 싶어 10점 줄게요^^',\n",
       " '평점에속지마시길시간낭비 돈낭비임',\n",
       " '리얼리티가 뛰어나긴 한데 큰 공감은 안간다. 이민기캐릭터는 정신의학상 분노조절장애 초기 증상일거다. 툭하면 사람패고 욕하고 물건 파손하고.. 조금 오바였음. 극 초반엔 신선했는데 가면 갈수록 이민기 정신상태 공감불가.',\n",
       " '마이너스는 왜없냐 ㅋ 뮤비 보고 영화수준 딱 알만하더군 ㅉㅉ 북한에서 이런거 만들라고 돈 대주던?',\n",
       " '난 우리영화를 사랑합니다....^^;',\n",
       " '데너리스 타르 가르엔...나도 용의주인이 되고 싶다...누이랑,근친상간이나 하고 다닐지라도,소설 속에선 제일 멋진 놈이 자이메 라니스터였는데,드라마속에선,드래곤(용)이 제일 멋지네(웃음)감독님 토르-2 다크 월드는 말아 잡수셨을지라도,기본 선방은 했음']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#simplify\r\n",
    "\r\n",
    "import re\r\n",
    "\r\n",
    "docs = dataset['train']['document'] + dataset['test']['document']\r\n",
    "label = dataset['train']['label'] + dataset['test']['label']\r\n",
    "\r\n",
    "processed_docs = [re.sub(\"[\\s]+\", \" \", re.sub(\"[^가-힣a-zA-Z0-9]\", \" \", doc)) for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "processed_docs[20:50]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['나름 심오한 뜻도 있는 듯 그냥 학생이 선생과 놀아나는 영화는 절대 아님',\n",
       " '보면서 웃지 않는 건 불가능하다',\n",
       " '재미없다 지루하고 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남 바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 이건 볼게없다 음식도 별로 안나오고 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ',\n",
       " '절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다 ',\n",
       " '주제는 좋은데 중반부터 지루하다',\n",
       " '다 짤랐을꺼야 그래서 납득할 수 없었던거야 그럴꺼야 꼭 그랬던걸꺼야 ',\n",
       " 'kl2g 고추를 털어버려야 할텐데',\n",
       " '카밀라벨 발연기',\n",
       " '재밋는뎅',\n",
       " '센스있는 연출력 탁월한 캐스팅 90년대의 향수 그래서 9점 ',\n",
       " '엄포스의 위력을 다시 한번 깨닫게 해준 적 남 꽃검사님도 연기 정말 좋았어요 완전 명품드라마 ',\n",
       " '졸쓰레기 진부하고말도안됌 아 시간아까워',\n",
       " '재밌는데 별점이 왜이리 낮은고',\n",
       " '1 라도 기대했던 내가 죄인입니다 죄인입니다 ',\n",
       " '아직도 이 드라마는 내인생의 최고 ',\n",
       " '패션에 대한 열정 안나 윈투어 ',\n",
       " '키이라 나이틀리가 연기하고자 했던건 대체 정신장애일까 틱장애일까',\n",
       " '허허 원작가 정신나간 유령이라 재미있겠네요 ',\n",
       " '포스터는 있어보이는데 관객은 114명이네',\n",
       " '이 영화가 왜 이렇게 저평가 받는지 모르겠다',\n",
       " '단순하면서 은은한 매력의 영화',\n",
       " ' 다 알바생인가 내용도 없고 무서운거도 없고 웃긴거도 하나도 없음 완전 별싱거운 영화 내 시간 넘 아까움 완전 낚임',\n",
       " '오게두어라 서리한이 굶주렸다 ',\n",
       " '정말 맘에 들어요 그래서 또 보고싶은데 또 보는 방법이 없네 ',\n",
       " '윤제문이라는 멋진 배우를 발견하게 됐어요 소소한 일탈이 잔잔한 미소를 머금게 합니다 음악은 조금 아쉽네요 8점 주고 싶은데 평점 올리고 싶어 10점 줄게요 ',\n",
       " '평점에속지마시길시간낭비 돈낭비임',\n",
       " '리얼리티가 뛰어나긴 한데 큰 공감은 안간다 이민기캐릭터는 정신의학상 분노조절장애 초기 증상일거다 툭하면 사람패고 욕하고 물건 파손하고 조금 오바였음 극 초반엔 신선했는데 가면 갈수록 이민기 정신상태 공감불가 ',\n",
       " '마이너스는 왜없냐 뮤비 보고 영화수준 딱 알만하더군 북한에서 이런거 만들라고 돈 대주던 ',\n",
       " '난 우리영화를 사랑합니다 ',\n",
       " '데너리스 타르 가르엔 나도 용의주인이 되고 싶다 누이랑 근친상간이나 하고 다닐지라도 소설 속에선 제일 멋진 놈이 자이메 라니스터였는데 드라마속에선 드래곤 용 이 제일 멋지네 웃음 감독님 토르 2 다크 월드는 말아 잡수셨을지라도 기본 선방은 했음']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# tokenize\r\n",
    "\r\n",
    "# from konlpy.tag import Mecab\r\n",
    "#\r\n",
    "# mecab = Mecab()\r\n",
    "\r\n",
    "# res = []\r\n",
    "\r\n",
    "# for doc in docs:\r\n",
    "#   tokenlist = mecab.pos(doc)\r\n",
    "#   for w in tokenlist:\r\n",
    "#     if w[1] in ['NNG', 'NNP', 'NNB', 'NNBC', 'NP' 'VV', 'VA', 'IC', 'SN', 'SL', 'MAG', 'MAJ']:\r\n",
    "#       res.append(w[1])\r\n",
    "\r\n",
    "from konlpy.tag import Okt\r\n",
    "\r\n",
    "okt = Okt()\r\n",
    "\r\n",
    "res = []\r\n",
    "\r\n",
    "\r\n",
    "for doc in processed_docs:\r\n",
    "  tokenlist = okt.pos(doc, norm=True, stem = True)\r\n",
    "  temp = []\r\n",
    "  for w in tokenlist:\r\n",
    "    if w[1] in ['Noun', 'Adjective', 'Adverb', 'Alpha', 'Exclamation', 'Foreign', 'Alpha', 'KoreanParticle', 'Number']:\r\n",
    "      temp.append(w[0])\r\n",
    "  res.append(temp)\r\n",
    "\r\n",
    "res[20:50]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['나름', '심오하다', '뜻', '있다', '듯', '그냥', '학생', '선생', '영화', '절대', '아니다'],\n",
       " ['건', '불가능하다'],\n",
       " ['재미없다',\n",
       "  '지루하다',\n",
       "  '같다',\n",
       "  '음식',\n",
       "  '영화',\n",
       "  '도',\n",
       "  '바베트',\n",
       "  '만찬',\n",
       "  '바베트',\n",
       "  '만찬',\n",
       "  '이야기',\n",
       "  '있다',\n",
       "  '음식',\n",
       "  '재미',\n",
       "  '있다',\n",
       "  '것',\n",
       "  '볼',\n",
       "  '없다',\n",
       "  '음식',\n",
       "  '별로',\n",
       "  '핀란드',\n",
       "  '풍경',\n",
       "  '할랫',\n",
       "  '그것',\n",
       "  '별로'],\n",
       " ['절대', '평범하다', '영화', '아니다', '수작', '는걸'],\n",
       " ['주제', '좋다', '중반', '지루하다'],\n",
       " ['다', '짤랐을꺼', '그래서', '납득', '수', '없다', '그렇다', '꼭', '그렇다'],\n",
       " ['kl', '2', 'g', '고추'],\n",
       " ['카밀라', '벨', '발연기'],\n",
       " ['재밌다', '뎅'],\n",
       " ['센스', '있다', '연출', '탁월하다', '캐스팅', '90년', '대의', '향수', '그래서', '9', '점'],\n",
       " ['엄포스',\n",
       "  '위력',\n",
       "  '다시',\n",
       "  '한번',\n",
       "  '적',\n",
       "  '남',\n",
       "  '꽃',\n",
       "  '검사',\n",
       "  '연기',\n",
       "  '정말',\n",
       "  '좋다',\n",
       "  '완전',\n",
       "  '명품',\n",
       "  '드라마'],\n",
       " ['졸', '쓰레기', '진부하다', '도안', '아', '시간', '아깝다'],\n",
       " ['재밌다', '점', '왜', '이리', '낮다'],\n",
       " ['1', '기대하다', '내', '죄인', '이다', '죄인', '이다'],\n",
       " ['아직도', '이', '드라마', '인생', '최고'],\n",
       " ['패션', '대한', '열정', '안나', '윈', '투어'],\n",
       " ['키이라', '나이틀리', '연기', '대체', '정신장애', '틱장애'],\n",
       " ['허허', '원작', '정신', '유령', '재미있다'],\n",
       " ['포스터', '있다', '관객', '114', '명'],\n",
       " ['이', '영화', '왜', '이렇게', '평가'],\n",
       " ['단순하다', '은은하다', '매력', '영화'],\n",
       " ['다',\n",
       "  '알바생',\n",
       "  '내용',\n",
       "  '없다',\n",
       "  '무섭다',\n",
       "  '없다',\n",
       "  '하나',\n",
       "  '없다',\n",
       "  '완전',\n",
       "  '별',\n",
       "  '싱겁다',\n",
       "  '영화',\n",
       "  '내',\n",
       "  '시간',\n",
       "  '아깝다',\n",
       "  '움',\n",
       "  '완전',\n",
       "  '낚임'],\n",
       " ['서리', '이'],\n",
       " ['정말', '맘', '그래서', '또', '또', '방법', '없다'],\n",
       " ['윤제문',\n",
       "  '멋지다',\n",
       "  '배우',\n",
       "  '발견',\n",
       "  '소소하다',\n",
       "  '탈',\n",
       "  '잔잔하다',\n",
       "  '미소',\n",
       "  '먹음',\n",
       "  '음악',\n",
       "  '조금',\n",
       "  '아쉽다',\n",
       "  '8',\n",
       "  '점',\n",
       "  '평점',\n",
       "  '10',\n",
       "  '점'],\n",
       " ['평점', '속지', '시간', '낭비', '돈', '낭비', '임'],\n",
       " ['리얼리티',\n",
       "  '뛰어나다',\n",
       "  '공감',\n",
       "  '안',\n",
       "  '간다',\n",
       "  '이민기',\n",
       "  '캐릭터',\n",
       "  '정신의학',\n",
       "  '분노조절',\n",
       "  '장애',\n",
       "  '초기',\n",
       "  '증상',\n",
       "  '툭하면',\n",
       "  '사람',\n",
       "  '패',\n",
       "  '욕',\n",
       "  '물건',\n",
       "  '파손',\n",
       "  '조금',\n",
       "  '바',\n",
       "  '초반',\n",
       "  '신선하다',\n",
       "  '가면',\n",
       "  '갈수록',\n",
       "  '이민기',\n",
       "  '정신',\n",
       "  '상태',\n",
       "  '공감',\n",
       "  '불가'],\n",
       " ['마이너스', '왜', '없다', '뮤비', '보고', '영화', '수준', '딱', '알', '북한', '이렇다', '돈'],\n",
       " ['난', '우리', '영화', '사랑'],\n",
       " ['데',\n",
       "  '리스',\n",
       "  '타르',\n",
       "  '용의',\n",
       "  '주인',\n",
       "  '누',\n",
       "  '근친상간',\n",
       "  '소설',\n",
       "  '속',\n",
       "  '제일',\n",
       "  '멋지다',\n",
       "  '놈',\n",
       "  '자',\n",
       "  '메',\n",
       "  '니스',\n",
       "  '터',\n",
       "  '드라마',\n",
       "  '속',\n",
       "  '드래곤',\n",
       "  '용',\n",
       "  '이',\n",
       "  '제일',\n",
       "  '멋지다',\n",
       "  '웃음',\n",
       "  '감독',\n",
       "  '토르',\n",
       "  '2',\n",
       "  '다크',\n",
       "  '월드',\n",
       "  '말',\n",
       "  '기본',\n",
       "  '선방']]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import pickle\r\n",
    "\r\n",
    "save = []\r\n",
    "\r\n",
    "for i in range(len(res)):\r\n",
    "  save.append(res[i], label[i])\r\n",
    "\r\n",
    "with open(\"senspos.pickle\", 'wb') as f:\r\n",
    "  pickle.dump(save, f)\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (2 given)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a39c6afb1095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0msave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"senspos.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# make v2v\r\n",
    "from gensim.models import Word2Vec\r\n",
    "\r\n",
    "model = Word2Vec(res, vector_size=300, window=5, min_count=5, workers=4, sg=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# load pretrained w2v\r\n",
    "import gensim\r\n",
    "\r\n",
    "model = gensim.models.Word2Vec.load('ko.bin')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\ford0\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-dc33e7263827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ko.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1933\u001b[0m \u001b[1;31m# Example: ./word2vec.py -train data.txt -output vec.txt -size 200 -window 5 -sample 1e-4 \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1934\u001b[1;33m \u001b[1;31m# -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1935\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1936\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewvectors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1922\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgained_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    484\u001b[0m                     \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                 \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m                 \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'indptr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                 \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'indices'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mnew_func2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m             warnings.warn(\n\u001b[0m\u001b[0;32m   1459\u001b[0m                 \u001b[0mfmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m                 \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\ford0\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('국민', 0.8718711137771606), ('인류', 0.8155882358551025), ('인권', 0.8078814148902893), ('카자흐스탄', 0.7713403701782227), ('실수', 0.7644094824790955), ('평화', 0.7597020864486694), ('국가', 0.7576998472213745), ('교회', 0.7549630999565125), ('길이', 0.7539796233177185), ('세계', 0.7535202503204346)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}